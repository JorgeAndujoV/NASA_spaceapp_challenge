import streamlit as st
import folium
from streamlit_folium import st_folium
import random
import datetime
import base64
import os

# <-- 1. IMPORTAMOS EL MODELO REAL DESDE model.py
# Le cambiamos el nombre a 'real_model_predict' para mayor claridad.
from model import mock_model_predict as real_model_predict

# =============================================================================
# 1. CONFIGURACI√ìN DE LA P√ÅGINA
# =============================================================================
st.set_page_config(
    page_title="Predictor de H√°bitat de Tiburones",
    page_icon="ü¶à",
    layout="wide",
)

# =============================================================================
# 2. ELIMINAMOS LA SIMULACI√ìN DEL MODELO
# =============================================================================
# La funci√≥n 'mock_model_predict' que generaba n√∫meros aleatorios ha sido BORRADA.
# Ahora usamos la funci√≥n real que importamos de 'model.py'.

# =============================================================================
# 3. FUNCIONES AUXILIARES (Esta se queda igual)
# =============================================================================
def get_probability_details(probability: float) -> tuple:
    """
    Categoriza la probabilidad en niveles y asigna un color y emoji.
    """
    if probability < 0.33:
        level = "Baja"
        color = "green"
        emoji = "üü¢"
    elif probability < 0.66:
        level = "Media"
        color = "orange"
        emoji = "üü†"
    else:
        level = "Alta"
        color = "red"
        emoji = "üî¥"
    return level, color, emoji

# =============================================================================
# 4. INICIALIZACI√ìN DEL ESTADO Y FUNCIONES DE UI
# =============================================================================
if "last_clicked" not in st.session_state:
    st.session_state["last_clicked"] = None

def autoplay_video(video_url: str):
    md = f"""
    <video controls loop autoplay="true" muted="true" style="width:100%;">
        <source src="{video_url}" type="video/webm">
    </video>
    """
    st.markdown(md, unsafe_allow_html=True)

# =============================================================================
# 5. CONSTRUCCI√ìN DE LA INTERFAZ GR√ÅFICA (UI)
# =============================================================================
st.title("¬øD√≥nde est√°n los tiburones? ü¶à")
st.markdown("Una herramienta para predecir h√°bitats de forrajeo de tiburones utilizando datos satelitales de la NASA.")

tab1, tab2, tab3 = st.tabs(["üåé Herramienta Predictiva", "üî¨ La Ciencia Detr√°s del Modelo", "üß† Nuestra Metodolog√≠a"])

# --- PESTA√ëA 1: HERRAMIENTA PREDICTIVA ---
with tab1:
    map_col, results_col = st.columns([3, 2])
    with results_col:
        st.header("Panel de an√°lisis")
        st.date_input(
            "Selecciona mes y a√±o:",
            value=datetime.date(2025, 10, 5),
            min_value=datetime.date(2020, 1, 1),
            max_value=datetime.date(2030, 12, 31),
            key='date_input'
        )
        st.markdown("---")
        results_placeholder = st.empty()

    with map_col:
        if st.session_state["last_clicked"]:
            location = [st.session_state["last_clicked"]["lat"], st.session_state["last_clicked"]["lng"]]
            zoom = 6
        else:
            location = [20, 0]
            zoom = 2.5
        m = folium.Map(location=location, zoom_start=zoom)

        if st.session_state["last_clicked"]:
            lat = st.session_state["last_clicked"]["lat"]
            lon = st.session_state["last_clicked"]["lng"]
            date = st.session_state.date_input
            
            # <-- 3. USAMOS EL MODELO REAL
            probability = real_model_predict(lat, lon, date.month, date.year)
            level, color, emoji = get_probability_details(probability)
            popup_text = f"""
            <b>Ubicaci√≥n Analizada</b><br>
            Lat: {lat:.2f}, Lon: {lon:.2f}<br>
            Probabilidad: <b>{probability:.0%} ({level})</b>
            """
            folium.Marker(
                location=[lat, lon],
                popup=folium.Popup(popup_text, max_width=300),
                icon=folium.Icon(color=color, icon="life-ring", prefix='fa')
            ).add_to(m)

        map_data = st_folium(m, height=600, width="100%", returned_objects=["last_clicked"])

        if map_data and map_data["last_clicked"]:
            st.session_state["last_clicked"] = map_data["last_clicked"]
            st.rerun()

    if st.session_state["last_clicked"]:
        lat = st.session_state["last_clicked"]["lat"]
        lon = st.session_state["last_clicked"]["lng"]
        date = st.session_state.date_input
        
        # <-- 3. USAMOS EL MODELO REAL (de nuevo para el panel)
        probability = real_model_predict(lat, lon, date.month, date.year)
        level, color, emoji = get_probability_details(probability)
        
        with results_placeholder.container():
            st.subheader(f"Resultado para el punto seleccionado:")
            st.metric(label=f"{emoji} Nivel de probabilidad", value=level)
            st.metric(label="Valor de probabilidad", value=f"{probability:.2%}")
            st.progress(probability)
            with st.expander("Detalles de la entrada"):
                st.write(f"**Latitud:** {lat:.4f}")
                st.write(f"**Longitud:** {lon:.4f}")
                st.write(f"**Fecha:** {date.strftime('%B %Y')}")
    else:
        with results_placeholder.container():
            st.info("‚ÑπÔ∏è Haz clic en un punto del mapa para iniciar el an√°lisis.")

# --- PESTA√ëA 2: SECCI√ìN DID√ÅCTICA ---
with tab2:
    # ... (Todo el c√≥digo de la Pesta√±a 2 se queda exactamente igual) ...
    st.header("Plancton y corrientes")
    st.write("Nuestro modelo funciona como un detective que busca dos pistas clave en el oc√©ano para encontrar los lugares preferidos de los tiburones. Estas pistas, invisibles al ojo humano, son capturadas por los sat√©lites de la NASA.")
    
    video_col1, video_col2 = st.columns(2)

    with video_col1:
        st.subheader("El Plancton, base de la cadena alimenticia")
        try:
            autoplay_video('https://raw.githubusercontent.com/JorgeAndujoV/NASA_spaceapp_challenge/main/plancton.webm') 
            st.caption("Cr√©dito: MIT Darwin Project, ECCO2, MITgcm")
        except Exception:
            st.warning("No se pudo cargar el video de plancton.")
    
        st.markdown(
            """
            El **fitoplancton** son algas microsc√≥picas que forman la base de toda la cadena alimenticia en el oc√©ano. 
            - **¬øPor qu√© es relevante?** Donde hay grandes concentraciones de plancton, hay peque√±os peces y crust√°ceos aliment√°ndose. Esto atrae a peces m√°s grandes, que a su vez, son el alimento principal de los tiburones.
            **Nuestra herramienta** utiliza las im√°genes satelitales de clorofila para identificar estas √°reas ricas en plancton, ayud√°ndonos a predecir d√≥nde es m√°s probable que los tiburones encuentren comida.
            """
        )

    with video_col2:
        st.subheader("Las corrientes, autopistas del oc√©ano")
        try:
            autoplay_video('https://raw.githubusercontent.com/JorgeAndujoV/NASA_spaceapp_challenge/main/currents.webm') 
            st.caption("Cr√©dito: NASA/Goddard Space Flight Center Scientific Visualization Studio")
        except Exception:
            st.warning("No se pudo cargar el video de corrientes.")
            
        st.markdown(
            """
            Las **corrientes oce√°nicas** act√∫an como r√≠os y autopistas que transportan nutrientes y agrupan a las presas.
            - **¬øPor qu√© es relevante?** Los tiburones son depredadores inteligentes. No gastan energ√≠a buscando al azar; utilizan las corrientes para viajar y patrullar zonas donde los remolinos y frentes oce√°nicos concentran a sus presas, como si fueran embudos.
            **Nuestra herramienta** emplea datos im√°genes satelitales de la NASA para identificar estas rutas y puntos calientes, ayud√°ndonos a predecir d√≥nde es m√°s probable que los tiburones patrullen en busca de alimento.
            """
        )

# --- PESTA√ëA 3: METODOLOG√çA Y PROPUESTA ---
with tab3:
    # ... (Todo el c√≥digo de la Pesta√±a 3 se queda exactamente igual) ...
    st.header("Datos satelitales y machine learning")
    st.write(
        """
        Nuestro primer objetivo fue transformar datos crudos del oc√©ano en una predicci√≥n √∫til y accesible. Para lograrlo, construimos un pipeline de Machine Learning de dos etapas que combina el aprendizaje no supervisado para entender el ambiente, y el aprendizaje supervisado para predecir la presencia de tiburones.
        """
    )
    st.markdown("---")
    img_col_cluster, text_col_cluster = st.columns([2, 3])

    with img_col_cluster:
        st.image(
            'enesep.png', 
            caption="Visualizaci√≥n de los cl√∫steres oceanogr√°ficos identificados por nuestro modelo, comparaci√≥n enero-septiembre de dos a√±os.",
            use_container_width=True
        )

    with text_col_cluster:
        st.subheader("1. Procesamiento de datos de la NASA")
        st.markdown(
            """
            Comenzamos con bases de datos de imagenes satelitales de la NASA que capturan variables oce√°nicas clave como la temperatura del mar, la salinidad, la clorofila (indicador de plancton) y las corrientes oce√°nicas.
            """
        )
        st.subheader("2. Cl√∫stering para entender el oc√©ano")
        st.markdown(
            """
            Para que nuestro modelo pudiera entender el oc√©ano, primero necesit√°bamos ense√±arle a reconocer diferentes "tipos" de ambientes. Analizamos varios algoritmos de clustering y seleccionamos aquel cuyas agrupaciones mostraron una fuerte correlaci√≥n con las clasificaciones oceanogr√°ficas de la NASA.

            Cada cl√∫ster representa una "etiqueta" para un ecosistema con caracter√≠sticas √∫nicas, permiti√©ndonos crear nuestros propios datasets de entrenamiento.
            """
        )

    st.markdown("---")
    st.subheader("3. Predicci√≥n de h√°bitats de tiburones")
    st.markdown(
        """
        Con el oc√©ano ya etiquetado por cl√∫steres, entrenamos una **red neuronal**. Esta f√≥rmula representa el **marco te√≥rico** de nuestro enfoque, donde la probabilidad de un tibur√≥n se calcula a partir de la probabilidad de cada tipo de ambiente:
        """
    )
    st.latex(r'''
        P(\text{shark}|x) = \sum_{k=1}^{K} P(\text{cluster} = k|x) P(\text{shark}|\text{cluster} = k, \text{time})
    ''')
    st.markdown(
        """
        Nuestra **red neuronal** es la implementaci√≥n que resuelve esta ecuaci√≥n. El modelo aprendi√≥ la relaci√≥n entre las caracter√≠sticas ambientales de cada cl√∫ster y la probabilidad de encontrar tiburones en esas zonas.

        La predicci√≥n final es una **"predicci√≥n proxy"** inteligente. El modelo utiliza patrones de los cl√∫steres adem√°s de conocimiento biol√≥gico sobre el comportamiento de los tiburones y las caracter√≠sticas del mar para estimar d√≥nde es m√°s probable que se encuentren.
        """
    )
    st.markdown("---")
    st.header("Propuesta de redise√±o de etiqueta de archivo satelital emergente")
    img_col_tag, text_col_tag = st.columns([2, 3])
    with img_col_tag:
        st.image(
            'tag.jpg',
            use_container_width=True,
            caption="Propuesta de tag satelital avanzado."
        )
    with text_col_tag:
        st.write(
            """
            El tag registrar√° informaci√≥n esencial del entorno y del comportamiento del tibur√≥n...
            """
        )